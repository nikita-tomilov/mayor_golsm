\section{Conclusion}

As shown in the article, the developed LSM storage library provides faster write and read operations for the time series data than SQLite. Also, it allows keeping data in case of unexpected application crashes due to commit log mechanism. In the best cases, this library is up to 50 times faster than SQLite for read operations, thanks to its $C_0$ level. It effectively serves as an in-memory cache, and up to 2 times faster than SQLite on write operations, due to the way how writing mechanisms work. However, the writing advantage is only valid if the time series data always have increasing timestamps. So the next written batch of data has bigger timestamp than the already written data for each tag. If this is not guaranteed, the data writing process is slowed down by an order of magnitude, making it slower than using SQLite. However, the benefits of multi-level storage for reading the data are still present. Varying the size of $C_0$ level can give the end-user the required balance between reading speed and RAM usage.

Using in any data logging use-case scenario, where the application has to store or buffer data that is continuously retrieved from various sensors, the timestamps for this data are naturally increasing. It removes the potential problem with writing randomized data and making the LSM-based storage engine a good alternative to SQLite, improving both read and write speeds.

The potential improvements of the developed library include splitting a single SST file per tag to multiple files, reducing the resorting time when the timestamp-randomized was written, and adjusting the in-memory layer so that its size can be different for different tags, for the use-cases where certain tags are requested more frequently and/or for bigger time ranges.